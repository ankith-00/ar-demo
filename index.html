<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
    <title>AR.js Responsive Video</title>

    <!-- A-Frame and AR.js -->
    <script src="https://aframe.io/releases/1.3.0/aframe.min.js"></script>
    <script src="https://raw.githack.com/AR-js-org/AR.js/3.4.5/aframe/build/aframe-ar.js"></script>

    <style>
      * {
        margin: 0;
        padding: 0;
        box-sizing: border-box;
      }

      html, body {
        width: 100%;
        height: 100%;
        overflow: hidden;
        font-family: Arial, sans-serif;
        position: fixed;
      }

      #status {
        position: fixed;
        bottom: 20px;
        left: 50%;
        transform: translateX(-50%);
        background: rgba(0, 0, 0, 0.7);
        color: white;
        padding: 10px 20px;
        border-radius: 5px;
        z-index: 999;
        font-size: 14px;
      }

      /* Force full screen AR scene */
      a-scene {
        position: fixed !important;
        top: 0 !important;
        left: 0 !important;
        width: 100vw !important;
        height: 100vh !important;
        margin: 0 !important;
        padding: 0 !important;
      }

      /* Canvas should fill entire screen */
      .a-canvas {
        width: 100vw !important;
        height: 100vh !important;
        position: fixed !important;
        top: 0 !important;
        left: 0 !important;
      }

      /* Camera feed video should cover full screen */
      .arjs-video, video[autoplay] {
        position: fixed !important;
        top: 50% !important;
        left: 50% !important;
        min-width: 100% !important;
        min-height: 100% !important;
        width: auto !important;
        height: auto !important;
        transform: translate(-50%, -50%) !important;
        object-fit: cover !important;
        z-index: -1 !important;
      }
    </style>
  </head>

  <body>
    <div id="status">ðŸ“· Point camera at marker to play video</div>

    <!-- AR Scene -->
    <a-scene
      embedded
      vr-mode-ui="enabled: false"
      renderer="logarithmicDepthBuffer: true; alpha: true; antialias: true;"
      arjs="sourceType: webcam; debugUIEnabled: false; patternRatio: 0.8; sourceWidth: 1280; sourceHeight: 960; displayWidth: 1280; displayHeight: 960;"
    >

      <!-- Video asset -->
      <a-assets>
        <video
          id="vid"
          src="https://commondatastorage.googleapis.com/gtv-videos-bucket/sample/BigBuckBunny.mp4"
          loop
          crossorigin="anonymous"
          playsinline
          webkit-playsinline
          preload="auto"
          muted
        ></video>
      </a-assets>

      <!-- Marker -->
      <a-marker
        id="marker"
        type="pattern"
        url="https://rawcdn.githack.com/ankith-00/ar-demo/refs/heads/main/marker.patt"
        emitevents="true"
      >
        <!-- Video plane with 16:9 aspect ratio (smaller size) -->
        <a-plane
          id="video-plane"
          position="0 0 0"
          rotation="-90 0 0"
          width="2"
          height="1.125"
          material="src: #vid; shader: flat; side: double; transparent: true;"
        ></a-plane>

        <!-- Optional border -->
        <a-box
          position="0 -0.05 0"
          rotation="-90 0 0"
          width="2.1"
          height="1.2"
          depth="0.05"
          color="#222"
        ></a-box>
      </a-marker>

      <a-entity camera look-controls="enabled: false"></a-entity>
    </a-scene>

    <!-- Video playback control script -->
    <script>
      const marker = document.querySelector('#marker');
      const video = document.querySelector('#vid');
      const status = document.querySelector('#status');
      let audioEnabled = false;

      // Wait for AR.js to initialize
      window.addEventListener('load', () => {
        setTimeout(() => {
          // Force camera feed to be visible and full screen
          const arVideos = document.querySelectorAll('video');
          arVideos.forEach(v => {
            if (v !== video && v.hasAttribute('autoplay')) {
              v.style.position = 'fixed';
              v.style.top = '50%';
              v.style.left = '50%';
              v.style.minWidth = '100%';
              v.style.minHeight = '100%';
              v.style.width = 'auto';
              v.style.height = 'auto';
              v.style.transform = 'translate(-50%, -50%)';
              v.style.objectFit = 'cover';
              v.style.zIndex = '-1';
            }
          });
        }, 500);
      });

      // Preload video
      video.load();

      // Ensure looping attribute is set
      video.loop = true;

      marker.addEventListener('markerFound', () => {
        status.textContent = audioEnabled ? 'âœ“ Playing with audio' : 'âœ“ Marker detected! Tap for audio';
        status.style.background = 'rgba(0, 200, 0, 0.7)';
        
        // Start playing video (muted initially for autoplay)
        video.play().catch(err => {
          console.error('Autoplay failed:', err);
        });
      });

      marker.addEventListener('markerLost', () => {
        status.textContent = 'âœ— Marker lost - point at marker';
        status.style.background = 'rgba(200, 0, 0, 0.7)';
        video.pause();
      });

      // Tap to enable audio
      document.body.addEventListener('click', () => {
        if (!audioEnabled) {
          video.muted = false;
          video.play()
            .then(() => {
              audioEnabled = true;
              status.textContent = 'ðŸ”Š Audio enabled! Video playing';
            })
            .catch(err => {
              console.error('Audio enable error:', err);
              status.textContent = 'âš ï¸ Error: Tap again to retry';
            });
        }
      });

      // Handle video end (backup loop mechanism)
      video.addEventListener('ended', () => {
        video.currentTime = 0;
        video.play();
      });
    </script>
  </body>
</html>